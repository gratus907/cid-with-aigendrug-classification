{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from datautil import *\n",
    "\n",
    "train_set, test_set = read_data_as_np(False)\n",
    "weighted_train_set, weighted_test_set = read_data_as_np(True)\n",
    "print(\"Loaded data\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded data\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "def X_Y_Split(data_points):\n",
    "    X, Y = [], []\n",
    "    for idx in range(len(data_points)):\n",
    "        x, y = data_points[idx]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def evaluate_classifier(classifier, test_data, title=\"\"):\n",
    "    print(f\"Evaluate {title}\")\n",
    "    testX, testY = X_Y_Split(test_data)\n",
    "    total = testY.shape[0]\n",
    "    testY = testY.ravel()\n",
    "    pred = classifier.predict(testX)\n",
    "    result = (pred==testY)\n",
    "    correct = (np.count_nonzero(result))\n",
    "    print(f\"{correct}/{total} correct ({100*correct/total:.3f}%)\")\n",
    "\n",
    "tX, tY = X_Y_Split(train_set)\n",
    "wtX, wtY = X_Y_Split(weighted_train_set)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import *\n",
    "from e3fp.fingerprint.metrics.array_metrics import soergel, tanimoto, dice, cosine, pearson\n",
    "\n",
    "poly_clf = SVC(kernel='poly', degree=5, probability=True, coef0=0)\n",
    "poly_clf.fit(wtX, wtY)\n",
    "evaluate_classifier(poly_clf, weighted_test_set, \"Degree 5 polynomial\")\n",
    "\n",
    "\n",
    "tanimoto_clf = SVC(kernel=tanimoto)\n",
    "tanimoto_clf.fit(tX, tY)\n",
    "evaluate_classifier(tanimoto_clf, test_set, \"e3fp-tanimoto\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/gratus/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluate Degree 5 polynomial\n",
      "135/207 correct (65.217%)\n",
      "Evaluate e3fp-tanimoto\n",
      "133/207 correct (64.251%)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/gratus/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "clf = SVC(kernel='rbf', gamma='auto')\n",
    "clf.fit(wtX, wtY)\n",
    "evaluate_classifier(clf, test_set, \"test\")\n",
    "print(tX[0])\n",
    "print(wtX[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/gratus/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluate test\n",
      "90/207 correct (43.478%)\n",
      "[1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0\n",
      " 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 6.1005  5.8649  0.      0.      0.      0.      0.      0.      0.\n",
      "  6.0396  6.3256  6.3953  6.0634  0.      5.9343  8.1757  0.      0.\n",
      "  0.      0.      0.      0.      0.     15.8496 15.3051  3.2193  0.\n",
      "  0.      0.      0.      0.      0.      0.     11.52    0.      0.\n",
      "  0.      9.5217  0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      6.8314  7.3451\n",
      "  0.      0.      0.      0.      0.      8.3458  7.7259  0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.     12.4793  0.      0.\n",
      "  0.      0.      5.8496  5.8496  0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      7.4543  0.     10.6926  0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      6.0837  6.1281  6.0543  0.     15.8496\n",
      "  0.      0.      0.      0.      0.     11.2262  9.3587  0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      6.224\n",
      "  6.7309  0.      0.      0.      0.      0.      0.      6.7043  0.\n",
      "  9.3587  0.      6.2059  4.3879  0.      0.      0.      0.      0.\n",
      "  6.1758  0.     11.3289  0.      7.1282  6.6333  0.      0.      0.\n",
      "  0.      0.      9.4342 14.4057 16.7807  4.2838  0.      0.      0.\n",
      "  0.      7.4454  7.7649  0.      0.      0.      0.     10.2346 11.8004\n",
      "  0.      0.      0.      0.      0.      0.      7.3697  0.      0.\n",
      "  0.      0.      0.      5.5529  2.5652  0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      7.2408  0.      8.4194  0.      0.     13.0485  0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      6.9459  6.9282\n",
      "  0.      0.      7.4748  0.      0.     10.      0.      0.      0.\n",
      "  7.1644  9.5981  0.      0.      0.      7.4483  0.      0.     10.5364\n",
      "  0.      0.      0.      6.7982  0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.     11.2338  0.      0.      0.\n",
      "  0.      0.      7.4339  0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      7.0955  0.      0.      0.      0.\n",
      "  8.7092  0.      0.      0.      0.      0.      9.4342  9.5818  8.8136\n",
      "  0.      0.      0.      0.     10.6413  0.      0.      0.      0.\n",
      "  0.      0.      0.      7.0627  0.      0.      0.      7.4339  0.\n",
      "  0.      0.      7.439   0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      9.6481  0.\n",
      "  4.1938  0.      0.      0.      0.     10.4363  9.927   0.      0.\n",
      " 11.8259  9.6523  0.      7.4213  0.      0.     10.4008  7.0955  0.\n",
      "  0.      0.      0.      0.      0.      0.      7.5442  0.      0.\n",
      "  0.      0.      6.6141  7.0426  0.      0.      0.      0.      0.\n",
      " 10.7155  0.      7.4213  0.      0.      0.      6.2891  0.      7.4339\n",
      "  8.8336  0.      0.      0.      0.      0.      9.4623  6.0438  0.\n",
      "  0.      7.2672  0.      0.      8.8452  6.9724 12.0231  0.      0.\n",
      "  7.4213  0.      0.      0.      8.1943  7.2672  0.      0.      6.4268\n",
      "  0.      5.45    0.      0.      0.      0.      7.3957  0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.     10.2405  0.\n",
      "  0.      0.      0.     12.0979  7.3311  0.      0.      0.      0.\n",
      "  0.      7.2072  0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      4.375\n",
      "  8.8336  0.      0.      7.3813  0.      0.      0.      7.5442 11.0434\n",
      "  0.      0.      7.3311  0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      7.4339  7.3813  6.7874  0.      0.      0.      6.2398\n",
      "  0.      0.      0.      0.      6.6651  0.      0.      0.      0.\n",
      "  0.      0.      0.      6.5407  6.8669  0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      6.8029  7.0371  6.8869\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  5.3051  0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  5.8496  0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      9.8185  0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  5.3051  0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  4.8543  0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      7.0895  0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.      0.      0.      0.    ]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}